---
title: "Homework 7"
subtitle: "Statistical Inference II"
author: "Noah Johnson"
date: "April 19, 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(install.load)
install_load('tidyverse')
install_load('haven')
install_load('broom')
install_load('ggplot2')
install_load('lme4')
```

In this homework, the data based on a sample of n = 176 chidren within J = 10 schools in the American subsample of the PISA (Programme for International Student Assessment) and is available in PISASchools10.sav. It has intentionally been provided in an .sav format so you will have to find the function to read a .sav file.

First, we will look at the relationship between student’s home education resources (HEDRES) on math achievement scores (MATHSCOR) across these 10 schools. Then, we will examine whether the schools’ press for academic excellence (ACADPRES) moderates this relationship. Read each question carefully, as there are multiple parts to most questions.    

*HEDRES*    scaled from 1 to 8; lower values indicate poor home resources for education

*MATHSCOR*    average of 50; SD of 9 points

*ACADPRES*    scaled from 1 to 8; lower values indicate low press for academic excellence

1. Use the *sav* data file to run separate multiple regression models for each of the 10 schools (X = *hedres*; Y = *mathscor*). Review the separate regression results for each of the schools. What do you notice about the results (look at the correlations between *mathscor* and *hedres*, and the regression coefficients for each of the 10 schools)? Is it reasonable to assume that the effect of home resources on math achievement is the same in all 10 schools? Why or why not? What does your answer imply regarding how to include the *hedres* variable within our HLM?

```{r}
# Read in data
data <- read_sav('PISASchools10.sav')

# Compute 10 different linear models
lms <- data %>% 
  group_by(schoolid) %>% 
  do(fit = lm(data = ., formula = mathscor ~ hedres), correlation = cor(.$mathscor, .$hedres)) %>% 
  mutate(correlation = unlist(correlation))

# Look at correlations
lms %>% select(schoolid, correlation) %>% ggplot(aes(x=factor(schoolid), y = correlation)) +
  geom_bar(stat = 'identity') +
  labs(x = 'School ID', y = 'Correlation', title = 'Correlations between mathscor and hedres')
```

**Schools 99143 and 99226 have a negative relationship between mathscor and hedres, while the other schools have a positive relationship.**

```{r}
# Look at regression coefficients
tidy(lms, fit)
```

**Here we see the same split, with two models having a negative slope. Clearly the effect of home resources on math achievement is NOT the same in all 10 schools. Thus Hedres should be included as a Level 1 effect within our HLM.**

2. MODEL 1: Using lme4 fit an unconditional random-effects ANOVA (i.e., *empty model*) with *mathscor* as the outcome. Report and interpret all the parameters as well as the ICC.

```{r}
model.empty <- lmer(mathscor ~ 1 + (1|schoolid), data = data)
model.empty.sum <- summary(model.empty)
model.empty.sum
```

$mathscor_{ij} = \beta_{0j} + r_{ij}$

$\beta_{0j} = \gamma_{00} + u_{0j}$

$\gamma_{00} = `r model.empty.sum$coefficients[1]`$ is the estimated grand mean math score.

$var(r_{ij}) = 58.19 = s^2$ is the within-group variance.

$var(u_{0j}) = 27.13$ is the between-group variance.

$ICC = \frac{27.13}{27.13 + 58.19} = `r (27.13)/(27.13 + 58.19)`$ is the intraclass correlation coefficient. Since it is not zero, some variance in mathscor is accounted for by schoolid.

3. MODEL 2: Run a *random coefficients model* with *hedres* (**group-mean centered**) as the predictor of math achievement. Report and interpret all the parameters. **Compared to Model 1**, how much was the within-schools variability ($s^2$) reduced with the addition of the group-centered home resources variable?

```{r}
school_group_means <- data %>%
  group_by(schoolid) %>%
  summarize(gpm_hedres = mean(hedres))

data <- merge(data, school_group_means, by = "schoolid")
data$hedres.group.mean.cen <- data$hedres - data$gpm_hedres

model2 <- lmer(mathscor ~ hedres.group.mean.cen + (hedres.group.mean.cen|schoolid), 
               data = data)
model2.sum <- summary(model2)
model2.sum
```

$mathscor_{ij} = \beta_{0j} + \beta_{1j}*(hedres_{ij} - \bar{hedres}_{j}) + r_{ij}$

$\beta_{0j} = \gamma_{00} + u_{0j}$

$\beta_{1j} = \gamma_{10} + u_{1j}$

$\gamma_{00} = `r model2.sum$coefficients[1,1]`$ is the estimated grand mean math score.

$\gamma_{10} = `r model2.sum$coefficients[2,1]`$ is the average effect of hedres on math score.

$var(r_{ij}) = 40.391 = s^2$ is the within-group variance.

$var(u_{0j}) = 28.11$ is the between-group variance of the intercept $\beta_{0j}$.

$var(u_{1j}) = 9.1$ is the between-group variance of the slope $\beta_{1j}$.

Compared to Model 1, $s^2$ was reduced by `r round(100*(58.19 - 40.391) / 58.19)`%.

4. Based on your results for step 3, would it make sense to eliminate the random effect for the home-resources slope ($u_{1j}$)? Why or why not?  Justify your decision.

If we're eliminating the random effect then we're saying that the slope of the hedres effect has the same variance across all schools. The between-group variance of the slope was estimated to be 9.1, with a 3.017 variance. This would pass a standard significance test, so we should not eliminate the random effect.
  
5. MODEL 3: Finally, run a *contextual or conditional model*, and add the school academic press (**centered at the grand-mean**) as a level-2 predictor of both the level-1 intercepts and the home-resources slopes. Report and interpret all the parameters. **Compared to Model 2**, was the variability in the intercepts between schools reduced with the addition of the academic press variable? What was the proportion reduction in this variance? What about the variability in home-resources slopes? Compared to Model 2, what proportion of this variance was accounted for by academic press?

```{r}
acadpres_grand_mean <- data %>%
  summarize(acadpres.grand.mean = mean(acadpres))

data$acadpres.grand.mean.cen <- data$acadpres - acadpres_grand_mean$acadpres.grand.mean

model3 <- lmer(mathscor ~ hedres.group.mean.cen * acadpres.grand.mean.cen +
                 (hedres.group.mean.cen|schoolid), data = data)
model3.sum <- summary(model3)
model3.sum
```

$mathscor_{ij} = \beta_{0j} + \beta_{1j}*(hedres_{ij} - \bar{hedres}_{j}) + r_{ij}$

$\beta_{0j} = \gamma_{00} + \gamma_{01} * (acadpres_j - \bar{acadpres}) + u_{0j}$

$\beta_{1j} = \gamma_{10} + \gamma_{11} * (acadpres_j - \bar{acadpres}) + u_{1j}$

$\gamma_{00} = `r model3.sum$coefficients[1,1]`$ is the estimated grand mean math score.

$\gamma_{10} = `r model3.sum$coefficients[2,1]`$ is the average effect of hedres on math score.

$\gamma_{01} = `r model3.sum$coefficients[3,1]`$ is the average effect of acadpres on math score.

$\gamma_{11} = `r model3.sum$coefficients[4,1]`$ is the average effect of acadpres on the average effect of hedres on math score, i.e. the effect of acadpres on the slope.

$var(r_{ij}) = 40.366 = s^2$ is the within-group variance.

$var(u_{0j}) = 3.00$ is the between-group variance of the intercept $\beta_{0j}$.

$var(u_{1j}) = 9.27$ is the between-group variance of the slope $\beta_{1j}$.

Compared to Model 2, the variability in the intercepts between schools was reduced by `r round(100*(28.11 - 3.00) / 28.11)`%.

Compared to Model 2, the variability in home-resources slopes between schools increased by `r round(100 * -(9.1 - 9.27) / 9.1)`%.
